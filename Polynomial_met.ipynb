{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#1. Método directo\n"],"metadata":{"id":"eftO4hiONFFo"}},{"cell_type":"markdown","source":[" El **método directo** (o **método del polinomio característico**) realmente no se basa en un método específico. Distintos autores (como los incluídos en la bibliografía) utilizan distintos métodos (como el método de Muller o el método de Durand–Kerner). Nosotros vamos a utilizar el **método de Newton**. La estrategia general de este método consiste en lo siguiente:\n","\n","<br>**1.** Determinar el polinomio característico de la matriz en cuestión.\n","\n","<br>**2.**  Determinar la derivada del polinomio característico.\n","\n","<br>**3.** Escoger una aproximación inicial.\n","\n","<br>**4.** Evaluar el polinomio característico en la aproximación inicial.\n","\n","<br>**5.** Evaluar la derivada del polinomio característico en la aproximación inicial.\n","\n","<br>**6.** Aplicar el método de Newton para aproximar una raíz.\n","\n","<br> Para hallar todas las raíces (reales) del polinomio característico (y por tanto los valores propios de la matriz), simplemente repetimos el procedimiento desde el paso 3, partiendo de una aproximación inicial diferente. También podemos llevar a cabo una **reducción** del polinomio característico. Dicha reducción se describe a continuación, para un polinomio de grado $n$ cualquiera:\n","\n","<br>$$P(x)=a_0+a_1 \\cdot x+a_2 \\cdot x^2...+a_n \\cdot x^n$$\n","\n","<br>Supongamos por un momento que conocemos una raíz $\\alpha_1$ de P. Entonces, por el algoritmo de la división para polinomios:\n","\n","<br>$$P(x)=(x-\\alpha_1) \\cdot Q(x)$$\n","\n","<br>donde $Q$ es un polinomio de grado $n-1$. Para hallar otra raíz de $P$, hallamos una raíz $\\alpha_2$ de $Q$. De este modo, aplicando nuevamente el algoritmo de la división para polinomios:\n","\n","<br>$$Q(x)=(x-\\alpha_2) \\cdot K(x)$$\n","\n","<br>donde $K$ es un polinomio de grado $n-2$. Luego:\n","\n","<br>$$P(x)=(x-\\alpha_1) \\cdot (x-\\alpha_2) \\cdot K(x)$$\n","\n","<br>Podemos seguir de este modo hasta hallar todas las raíces de $P$ (técnicamente, es suficiente seguir hasta obtener un cociente polinomial cuyo grado sea igual a 2, pues a partir de aquí podemos usar la fórmula general cuadrática para hallar las raíces que faltan).\n","\n","<br> En relación al método, aún hay varios aspectos que debemos discutir:\n","\n","<br>**-- Naturaleza de las raíces:** En el caso de las raíces simples (de multiplicidad 1) sabemos que la convergencia del método de Newton es cuadrática. En el caso de las raíces múltiples (de multiplicidad mayor que 1) la cuestión es un tanto más delicada. De acuerdo con Hoffman, una función no lineal tiende a cero más rápido que su derivada. Por lo tanto, en este caso también es posible usar el método de Newton, teniendo cuidado de interrumpir las iteraciones cuando la derivada del polinomio característico se aproxime a cero. Hay un problema, no obstante, y es que el método pasa de converger cuadráticamente a converger linealmente. Podemos solventar este problema de varias formas. Una de ellas consiste en modificar el método de Newton para recuperar la convergencia cuadrática.\n","\n","<br> La variante que vamos a considerar se conoce como **método de Newton modificado**. Dicha variante trata simplemente de aplicar el método de Newton a la función:\n","\n","<br>$$u(x)=\\frac{f(x)}{f'(x)}$$\n","\n","<br>donde $f$ es el polinomio de característico de una matriz A cualquiera. Supongamos que $f$ tiene una raíz $\\alpha$ de multiplicidad $m$. Entonces:\n","\n","<br>$$f(x)=(x-\\alpha)^m \\cdot h(x)$$\n","\n","<br>donde $h$ es un polinomio de grado $n-m$ tal que $h(\\alpha) \\neq 0$. Luego:\n","\n","<br>$$u(x)=\\frac{(x-\\alpha)^m \\cdot h(x)}{m \\cdot (x-α)^{m-1} \\cdot h(x)+(x-\\alpha)^m \\cdot h'(x)}$$\n","\n","<br> Es decir:\n","\n","<br> $$u(x)=\\frac{(x-\\alpha) \\cdot h(x)}{m \\cdot h(x)+(x-\\alpha) \\cdot h'(x)}$$\n","\n","<br> Como podemos ver, $u$ tiene una raíz simple en $x=\\alpha$. Con lo cual, es posible aplicar el método de Newton, con convergencia cuadrática, a la función $u$ para hallar la raíz $\\alpha$ de $f$.\n","\n","<br>A pesar de que recuperamos la convergencia cuadrática, siguen existiendo algunas desventajas. Para ver mejor ésto, apliquemos el método de Newton con la función $u$:\n","\n","<br>$$x_{i+1}=x_i-\\frac{u(x_i)}{u'(x_i)}$$\n","\n","<br>Es decir:\n","\n","<br>$$x_{i+1}=x_i-\\frac{f(x_i) \\cdot f'(x_i)}{[f'(x_i)]^2-f(x_i) \\cdot f''(x_i)}$$\n","\n","<br>Como podemos ver, en esta versión es necesario calcular $f''$. Adicionalmente, es necesario llevar a cabo más cálculos, lo que reduce la eficiencia y aumenta los errores de redondeo.\n","\n","<br>Nos falta mencionar el caso de las raíces complejas en pares conjugados. Sin embargo, ya que sólo estamos interesados en valores propios reales, no será necesario abordar esta cuestión.\n","\n","<br> **-- Eficiencia de los cálculos:** El método directo requiere evaluar varias veces el polinomio característico y su derivada en ciertos puntos. Para llevar a cabo dichas operaciones eficientemente, es común implementar dentro del método el **algoritmo de Horner**.\n","\n","<br> **-- Problemas asociados a las raíces:** Unos de los problemas más serios del método tiene que ver con la ausencia de una buena aproximación. Otros problemas asociados a las raíces son: determinación de la existencia de raíces múltiples; raíces muy próximas; raíces en puntos críticos o puntos de inflexión; convergencia a una raíz inesperada o incorrecta. Anteriormente analizamos una variante del método de Newton para abordar éste problema. En general, para abordar los problemas en cuestión, podemos utilizar otras herramientas tecnológicas, como un graficador de funciones, o llevar a cabo lo que Hoffman en su libro llama **incremental search method**.\n","\n","<br> **--Reducción polinomial:** Anteriormente describimos el proceso de reducción de un polinomio para hallar todas las raíces del mismo. Ésto es posible teóricamente, pero en la práctica puede ser problemático, pues estamos trabajando de hecho con raíces aproximadas y no necesariamente exactas. Consideremos nuevamente al polinomio $P$ de antes:\n","\n","<br>$$P(x)=a_0+a_1 \\cdot x+a_2 \\cdot x^2...+a_n \\cdot x^n$$\n","\n","Sabíamos que:\n","\n","<br>$$P(x)=(x-\\alpha_1) \\cdot Q(x)$$\n","\n","<br>Al obtener una raíz aproximada de $Q$, no necesariamente obtendremos una raíz aproximada de $P$. El **polinomio de Wilkinson** muestra a la perfección que las raíces de un polinomio pueden ser muy sensibles a pequeñas perturbaciones de sus coeficientes. Una forma de tratar de solventar el problema es la siguiente: una vez obtenemos una raíz aproximada $\\alpha_2$ de $Q$, aplicamos nuevamente el método de Newton a $P$ con aproximación inicial $\\alpha_2$ (en lugar de considerar directamente a $\\alpha_2$ como una raíz aproximada de $P$). Sin embargo, no hay garantía de que esto vaya a funcionar en todos los casos. La mejor forma de abordar este problema es utilizar métodos que aproximen simultáneamente todas las raíces del polinomio, como el **método de Alberth**.  \n","\n","\n","\n"],"metadata":{"id":"FjIP8FmnboPb"}},{"cell_type":"markdown","source":["##Implementación del método directo"],"metadata":{"id":"P7nDhA8g_EmP"}},{"cell_type":"code","source":["\n","import math\n","import numpy as np\n","from sympy import Matrix, symbols, diff\n","\n","def f(A):\n","    # Convertimos la lista a un array de NumPy\n","    A = np.array(A)\n","\n","    # Validamos si la matriz es cuadrada\n","    if A.shape[0] != A.shape[1]:\n","        raise ValueError(\"La matriz debe ser cuadrada para calcular el polinomio característico.\")\n","\n","    # Convertimos el array a una matriz de SymPy para usar métodos algebraicos\n","    A_sympy = Matrix(A)\n","\n","    # Declaramos el símbolo lambda para el polinomio característico\n","    lambd = symbols('λ')\n","\n","    # Calculamos el polinomio característico\n","    polinomio = A_sympy.charpoly(lambd).as_expr()\n","\n","    return polinomio\n","\n","def fdx(polinomio):\n","    # Declaramos el símbolo lambda para el polinomio característico\n","    lambd = symbols('λ')\n","    # Calculamos la derivada del polinomio\n","    derivada = diff(polinomio, lambd)\n","\n","    return derivada\n","\n","\n","# función para evaluar un punto en el polinomio característico\n","def f_evaluada(polinomio, punto):\n","  # Declaramos el símbolo lambda para el polinomio característico\n","    lambd = symbols('λ')\n","  # Se retorna el valor del polinomio\n","    return polinomio.subs(lambd, punto)\n","\n","# función para evaluar un punto en la derivada del polinomio característico\n","def fdx_evaluada(polinomio, punto):\n","  # Declaramos el símbolo lambda para el polinomio característico\n","    lambd = symbols('λ')\n","  # Se retorna el valor de la derivada del polinomio\n","    return fdx(polinomio).subs(lambd, punto)\n","\n","# función que aproximará el valor propio, dado un un punto inicial\n","def Newton_method(polinomio, p_0: float, tolerancia: float = 0.001, max_number_iter:int = 10):\n","    i : int = 1 # Se inicia un contador para saber el número de iteraciones\n","\n","    while i <= max_number_iter: # Se hacen las N iteraciones que se hayan declarado\n","\n","        p = float(p_0 - f_evaluada(polinomio,p_0)/fdx_evaluada(polinomio,p_0)) # Se aproxima el valor de la nueva iteración\n","        if abs(p-p_0)<tolerancia: # Se verifica si la diferencia entre la nueva iteriacion y la anterior es menor a la tolerancia declarada\n","            return p # Si esto ocurre, se retorna el valor de la iteracion\n","\n","        i += 1  #Se incrementa el contador por cada iteración\n","        p_0 = p # Se actualiza el valor de la iteración anterior, con el valor de la nueva iteración\n","\n","    # Si el error no es menor que la tolerancia al cabo de las N, se retorna lo siguiente.\n","    return f\"El método falló después de las {max_number_iter}\"\n"],"metadata":{"id":"MAfJHePBVrFk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","#### Casos de prueba:"],"metadata":{"id":"1vFuctJrGvO2"}},{"cell_type":"code","source":["\n","import numpy as np\n","\n","# Declaramos los vectores correspondientes para los casos de prueba.\n","vector = np.array([1, 1]) #Dimensión 2.\n","vector1 = np.array([1, 2, 0]) #Dimensión 3.\n","vector2 = np.array([1, 1, 1, 1]) #Dimensión 4.\n","\n","#Casos de prueba: declaramos un diccionario con las matrices de prueba.\n","\n","test = {\"A\": np.array([[2, 1], [3, 4]]),\n","       \"B\": np.array([[3, 2], [3, 4]]),\n","       \"C\": np.array([[2, 3], [1, 4]]),\n","       \"D\": np.array([[1, 1, 2], [2, 1, 1],[1, 1, 3]]),\n","       \"E\": np.array([[1, 1, 2], [2, 1, 3],[1, 1, 1]]),\n","       \"F\": np.array([[2, 1, 2], [1, 1, 3],[1, 1, 1]]),\n","       \"G\": np.array([[1, 1, 1, 2], [2, 1, 1, 1],[3, 2, 1, 2],[2, 1, 1, 4]]),\n","        \"H\": np.array([[1, 2, 1, 2], [2, 1, 1, 1],[3, 2, 1, 2],[2, 1, 1, 4]])}\n","\n","valor_inicial = 0\n","for name, matriz in test.items(): # iteramos sobre el diccionario con su respectiva clave y valor.\n","    #Utilizamos el metodo de Newton e imprimimos cada valor propio, correspondiente al valor inicial que se la haya pasado como parámetro.\n","    print(f\"La matriz {name} tiene el siguiente valor propio: {Newton_method(f(matriz),valor_inicial)} correspondiente al valor inicial {valor_inicial} \")\n","    valor_inicial += 1\n"],"metadata":{"id":"jH0NIo6gGu92","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c7e80926-1bcf-4b19-c081-f0fffa5f88d1","executionInfo":{"status":"ok","timestamp":1733519987110,"user_tz":300,"elapsed":823,"user":{"displayName":"Juan David Clavijo Fernández","userId":"01858053487129419089"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["La matriz A tiene el siguiente valor propio: 0.9999999999737855 correspondiente al valor inicial 0 \n","La matriz B tiene el siguiente valor propio: 1.0 correspondiente al valor inicial 1 \n","La matriz C tiene el siguiente valor propio: 0.9999999070777055 correspondiente al valor inicial 2 \n","La matriz D tiene el siguiente valor propio: -0.2851435433398339 correspondiente al valor inicial 3 \n","La matriz E tiene el siguiente valor propio: 4.048917339522421 correspondiente al valor inicial 4 \n","La matriz F tiene el siguiente valor propio: 4.124885445932234 correspondiente al valor inicial 5 \n","La matriz G tiene el siguiente valor propio: 6.634534720780106 correspondiente al valor inicial 6 \n","La matriz H tiene el siguiente valor propio: 6.827262252354639 correspondiente al valor inicial 7 \n"]}]},{"cell_type":"markdown","source":["\n","\n","##Conclusiones\n","\n","<br>--**Ventajas y desventajas del método directo:** Aquí nos referimos al método directo tal como se describió antes. Entre las ventajas del método directo encontramos: bajo ciertas condiciones, el método es preciso y converge rápidamente. Es una opción razonable para matrices pequeñas. Algunas desventajas: para matrices grandes, el coste computacional aumenta significativamente (por la cantidad de operaciones que es necesario llevar a cabo; entre ellas, por ejemplo, determinar el polinomio característico). Por razones similares al punto anterior, el método puede ser numéricamente inestable. Como vimos, si hay valores propios repetidos, el método converge más lento, y puede incluso fallar."],"metadata":{"id":"OuJyj8ei3x_G"}}]}