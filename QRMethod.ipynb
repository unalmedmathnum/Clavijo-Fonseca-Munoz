{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#3. Algoritmo QR\n",
        "\n",
        "El método directo y el método de potencia permiten determinar un valor propio a la vez. El **algoritmo QR** o **método de descomposición QR**, en cambio, nos permite determinar todos los valores propios de una matriz.\n",
        "\n",
        "<br>La parte esencial del algoritmo QR es la **descomposición QR** de una matriz. Existen varias formas de determinar dicha descomposición. Algunas de ellas son: el **proceso de ortogonalización de Gram-Schmidt**, mediante **rotaciones de Givens** y mediante **reflexiones de Householder**. En la implementación del algoritmo vamos a utilizar la función **linalg.qr** de Numpy para determinar la descomposición QR de una matriz $A$. Dicha función hace uso de las reflexiones de Householder para hallar la descomposición en cuestión. La intuición detrás del proceso es la siguiente: las reflexiones de Householder se aplican secuencialmente para \"eliminar\" los elementos por debajo de la diagonal de $A$, convirtiéndola en una matriz triangular superior $R$. Al mismo tiempo, las transformaciones acumuladas forman la matriz ortogonal $Q$. El costo computacional de éste método es similar al del proceso de ortogonalización de Gram-Schmidt (aunque es importante aclarar que se suele preferir el primero, pues el segundo suele \"sufrir\" más por los errores de redondeo). Nosotros, por simplicidad (para no perdernos en detalles ajenos al método como tal), vamos a utilizar la función mencionada para llevar a cabo la parte de la descomposición QR, sin profundizar en las reflexiones de Householder. Sin embargo, de ser absolutamente necesario, podríamos implementar fácilmente el conocido proceso de ortogonalización de Gram-Schmidt para llevar a cabo esta tarea.\n",
        "\n",
        "<br>La estrategia general del algoritmo QR consiste en lo siguiente:\n",
        "\n",
        "<br>1. Consideramos $A_0=A$.\n",
        "\n",
        "<br>2. Hallamos la descomposición QR de $A_0$, para obtener $A_0=Q_0R_0$.\n",
        "\n",
        "<br>3. Consideramos $A_1=R_0Q_0$.\n",
        "\n",
        "<br>Lo que sigue es repetir el procedimiento antes dado, reemplazando el papel de $A_0$ con el de $A_1$, y continuar con las iteraciones. De este modo, tendremos en general que:\n",
        "\n",
        "<br>-- Si $n$ es par, $A_n=Q_nR_n$. Ésto es: determinamos la descomposición QR de $A_n$.\n",
        "\n",
        "<br>-- Si $n$ es impar, $A_n=R_{n-1}Q_{n-1}$. Ésto es: consideramos la matriz a la cual le hallaremos la descomposición QR en el siguiente paso.\n",
        "\n",
        "<br>Las matrices $A_n$ y $A_{n+1}$ son **semejantes**, lo que nos asegura que tienen los mismos valores propios (pero no los mismos vectores propios). Ésto nos asegura, por así decirlo, que durante las iteraciones no perdemos de vista los valores propios de la matriz A. Además, la matriz $A_n$ se aproxima a una matriz triangular superior, en la cual podemos encontrar los valores propios en la diagonal principal. Ésta aproximación de $A_n$ a una matriz triangular superior no se justifica en ningún libro de la bibliografía. Está demostrada, por supuesto, pero la cuestión parece ser un poco difícil, por lo que tampoco será abordada aquí. Bastará decir que, intuitivamente, el algoritmo QR \"reorganiza\" progresivamente la matriz $A$ para reflejar mejor su estructura espectral, reduciendo las entradas fuera de la diagonal.\n",
        "\n",
        "<br>De acuerdo con Hoffman, la convergencia del algoritmo está asegurada (por lo general), aunque podría ser algo lenta. Para acelerar la convergencia, se suelen llevar a cabo dos modificaciones:\n",
        "\n",
        "<br>-- **Transformar la matriz de partida:** Generalmente lo que se hace es transformar la matriz $A$ en otra matriz \"casi\" triangular. Formalmente, se utilizan **transformaciones de Householder** para convertir la matriz $A$ en una **matriz de Hessenberg**.\n",
        "\n",
        "<br>-- **Shifting:** Mediante lo que Hoffman llama \"shifting\" de los valores propios de la matriz de Hessenberg de la cual se parte, a medida que se ejecuta el algoritmo, se puede mejorar significativamente la convergencia del método. Hay varias formas de llevar a cabo dicho \"shifting\", de acuerdo a ciertas consideraciones.\n",
        "\n"
      ],
      "metadata": {
        "id": "7O74-vH2OIvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implementación del algoritmo QR"
      ],
      "metadata": {
        "id": "VpCDN9Khqzkw"
      }
    },
    {
      "metadata": {
        "id": "gvFCr9PKhsAB"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 2,
      "source": [
        "\n",
        "import numpy as np #importamos la librería numpy que utilizaremos para trabajar con matrices\n",
        "\n",
        "#La siguiente función toma como parámetros una Lista de tamaño nxn, un número máximo de iteraciones opcional,\n",
        "#que por defecto será 100, y una tolerancia numérica, también opcional\n",
        "def QRDecomposition(A, maxIteraciones = 1000, tol = 1e-10):\n",
        "    A_n = np.array(A) #Convertimos la lista en un array de numpy para operar con el fácilmente\n",
        "\n",
        "    for i in range(maxIteraciones): #Comenzamos a iterar el método\n",
        "\n",
        "        #Cuando i es par:\n",
        "        if i%2 == 0:\n",
        "            Q_n,R_n = np.linalg.qr(A_n) #Descomposición QR de la matriz usando la función integrada de numpy\n",
        "\n",
        "        #Cuando i es impar\n",
        "        if i%2 == 1:\n",
        "            A_n = R_n@Q_n\n",
        "\n",
        "    \"\"\"Sabemos que en este método los valores que convergen a los valores propios están ubicados\n",
        "     sobre la diagonal de la matriz A_n, entonces vamos a recorrer esa diagonal y guardarlos en una lista\"\"\"\n",
        "\n",
        "    valoresPropios = [] #Creamos la lista\n",
        "    for i in range(A_n.shape[0]): #.shape[0] es para contar el número de filas, el cual será igual al numero de valores en la diagonal\n",
        "                                  #dado que la matriz es cuadrada\n",
        "        valoresPropios.append(A_n[i,i]) #Ingresamos los valores con índice [i,i] en la diagonal\n",
        "\n",
        "    return valoresPropios"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Declaramos los vectores correspondientes para los casos de prueba.\n",
        "vector = np.array([1, 1]) #Dimensión 2.\n",
        "vector1 = np.array([1, 2, 0]) #Dimensión 3.\n",
        "vector2 = np.array([1, 1, 1, 1]) #Dimensión 4.\n",
        "\n",
        "#Casos de prueba: declaramos un diccionario con las matrices de prueba.\n",
        "\n",
        "test = {\"A\": np.array([[2, 1], [3, 4]]),\n",
        "       \"B\": np.array([[3, 2], [3, 4]]),\n",
        "       \"C\": np.array([[2, 3], [1, 4]]),\n",
        "       \"D\": np.array([[1, 1, 2], [2, 1, 1],[1, 1, 3]]),\n",
        "       \"E\": np.array([[1, 1, 2], [2, 1, 3],[1, 1, 1]]),\n",
        "       \"F\": np.array([[2, 1, 2], [1, 1, 3],[1, 1, 1]]),\n",
        "       \"G\": np.array([[1, 1, 1, 2], [2, 1, 1, 1],[3, 2, 1, 2],[2, 1, 1, 4]]),\n",
        "        \"H\": np.array([[1, 2, 1, 2], [2, 1, 1, 1],[3, 2, 1, 2],[2, 1, 1, 4]])}\n",
        "\n",
        "for nombre, matriz in test.items(): #Creamos un ciclo que recorre el diccionario y va probando cada caso\n",
        "  print(f\"Los valores propios de la matriz {nombre} son:\")\n",
        "  print(QRDecomposition(matriz)) #Utilizamos la funcion QRDecomposition e imprimimos cada valor propio\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f56D79ymZZzp",
        "outputId": "ec9468a0-05f3-440e-c738-a4576a6426ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los valores propios de la matriz A son:\n",
            "[4.999999999999999, 0.9999999999999997]\n",
            "\n",
            "Los valores propios de la matriz B son:\n",
            "[5.999999999999998, 1.0000000000000002]\n",
            "\n",
            "Los valores propios de la matriz C son:\n",
            "[5.0, 1.0]\n",
            "\n",
            "Los valores propios de la matriz D son:\n",
            "[4.507018644092973, 0.7781238377368096, -0.28514248182978574]\n",
            "\n",
            "Los valores propios de la matriz E son:\n",
            "[4.048917339522307, -0.692021471630096, -0.3568958678922091]\n",
            "\n",
            "Los valores propios de la matriz F son:\n",
            "[4.124885419764577, -0.7615571818318913, 0.6366717620673171]\n",
            "\n",
            "Los valores propios de la matriz G son:\n",
            "[6.634534463633592, 1.5085633449433231, -0.7356415384387974, -0.4074562701381241]\n",
            "\n",
            "Los valores propios de la matriz H son:\n",
            "[6.827262250104039, 1.7281159082896407, -1.0879349236625606, -0.4674432347311208]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conclusiones\n",
        "\n",
        "<br>--**Ventajas y desventajas del método directo:** Aquí nos referimos al método directo que utiliza a su vez el método de Newton. Entre las ventajas del método directo encontramos: bajo ciertas condiciones, el método es preciso y converge rápidamente. Es una opción razonable para matrices pequeñas. Algunas desventajas: para matrices grandes, el coste computacional aumenta significativamente (por la cantidad de operaciones que es necesario llevar a cabo; entre ellas, por ejemplo, determinar el polinomio característico). Por razones similares al punto anterior, el método puede ser numéricamente inestable. Como vimos, si hay valores propios repetidos, el método converge más lento, y puede incluso fallar.\n",
        "\n",
        "<br>--**Ventajas y desventajas del método de las potencias:** Entre las ventajas del método de las potencias encontramos: es fácil y eficiente de implementar, dado que solo necesita operaciones básicas y el almacenamiento de pocos elementos (una matriz y un vector en cada iteración). Es especialmente útil para matrices grandes y **dispersas**. El hecho de encontrar el vector propio asociado al valor propio dominante también es una ventaja, pues los otros métodos solamente determinan valores propios.  Algunas desventajas: solamente encuentra el valor propio dominante. Requiere de matrices bien condicionadas y con espectros sencillos (se mencionó, por ejemplo, que si el valor propio dominante no está claramente separado de los demás, la convergencia del método podría ser lenta o inestable).  \n",
        "\n",
        "<br>--**Ventajas y desventajas del algoritmo QR:** Entre las ventajas del algoritmo QR encontramos: determina todos los valores propios de la matriz. El método es estable y funciona bien incluso para matrices mal condicionadas. Algunas desventajas: es computacionalmente costoso. Converge lentamente. Las operaciones que se llevan a cabo durante el método (en particular, la factorización QR) requieren un consumo de memoria considerable."
      ],
      "metadata": {
        "id": "OuJyj8ei3x_G"
      }
    }
  ]
}